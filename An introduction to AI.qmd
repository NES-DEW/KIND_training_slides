{{< include header.qmd >}}

## Welcome
+ this session is üå∂: for beginners
+ it aims to do two things:
1. to suggest that the term AI is troublesome
2. to introduce some of the different technologies that get lumped together as AI

## The KIND network

-   a social learning space for staff working with **k**nowledge, **i**nformation, and **d**ata across health, social care, and housing in Scotland
-   we offer social support, free training, mentoring, community events, ...
-   [Teams channel](https://teams.microsoft.com/l/team/19%3AQZ7-PbFVcziG2piHLt1_ifey3I2cwFL0yBuTSS8vVao1%40thread.tacv2/conversations?groupId=106d08f3-9026-40e2-b3c7-87cd87304d58&tenantId=10efe0bd-a030-4bca-809c-b5e6745e499a) / [mailing list](https://forms.office.com/pages/responsepage.aspx?id=veDvEDCgykuAnLXmdF5JmpopIZB9ynRJnrPUHVFccipURjM2NkZJUkhGOFlQRjQxRFhVUTgwT0UwVyQlQCN0PWcu)

## Future sessions {.smaller}

```{r}
KINDR::training_sessions(start_date = params$date, n = 5)
```


## A philosophical question
+ do submarines swim?

## Hype

-   There's a *lot* of hype about AI at the moment (see [this graph](https://www.google.com/imgres?imgurl=https%3A%2F%2Fassets.bwbx.io%2Fimages%2Fusers%2FiqjWHBFdfxIU%2Fi8RUqd2T_1Bs%2Fv2%2FpidjEfPlU1QWZop3vfGKsrX.ke8XuWirGYh1PKgEw44kE%2F-1x-1.png&tbnid=TPmvfqSuBPNC2M&vet=12ahUKEwjw5fuQs4WHAxUkU6QEHZyfDdkQMygDegQIARBP..i&imgrefurl=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2024-06-06%2Fnvidia-microsoft-and-apple-are-bigger-than-china-s-stock-market&docid=beNq4RhizA7SbM&w=1200&h=675&q=nvidia%20microsoft%20graph&ved=2ahUKEwjw5fuQs4WHAxUkU6QEHZyfDdkQMygDegQIARBP))
-   Underneath the hype, there's a lot of genuinely exciting stuff going on too
-   That exciting stuff is likely to have some impact on health and care work

## Motive

1. The *intelligence* part of AI is as misleading as a swimming submarine
1. There are lots of different technologies that currently fall under the AI umbrella
1. Points 1. and 2. matter in a practical way because of the hype </br> ![So hot right now screenshot from Zoolander](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRzbu0IXXvTWSW4Bim6PWKkjJQyn6PL7au6LQ&s){height="300px"}

# Three questions for you

## What does AI mean to you?

. . .

::: {layout-nrow="1"}
![](src/images/hal.jpg){width="400" height="400"}

![](src/images/arnie.jpg){width="400" height="400"}

![](src/images/pope.jpg){width="400" height="400"}

![](src/images/siri.jpg){width="400" height="400"}
:::

## Is AI...
+ Over-hyped?
+ Somewhere in between?
+ Neglected?
+ Other / don't know

## About this talk

Two problems:
- a worry about intelligence: based on the swimming submarine
- a worry about diversity: AI is several things, not just one thing


## The Chinese room

@searle1980

> "Suppose that I'm locked in a room and given a large batch of Chinese writing. Suppose furthermore (as is indeed the case) that I know no Chinese, either written or spoken, and that I'm not even confident that I could recognize Chinese writing"

. . .


However, he is supplied with a set of intelligible rules for manipulating these Chinese symbols

. . .


"ÁÅ´" is the opposite of "Ê∞¥"

"ÂÖ≠" is more than "Âõõ"

## Question

Does this poor bloke locked in a room understand the Chinese symbols?

. . .

Now suppose that we start asking him questions (in English):

. . .

Is "ÂÖ≠" more than "Âõõ"?

If so, respond with "ÊòØ". Otherwise respond "‰∏ç"



## Question

-   Is understanding the same thing as being able to produce output in response to input?

- @searle1980 - this is the difference between strong and weak AI


## Back to nice safe words

-   we usually don't worry too much about what words like intelligence, understanding, etc really mean
-   for most purposes, understanding something, and doing that thing, pretty well overlap
-   AI, unfortunately, is an exception
-   big difference between producing output and understanding here

## Why does this matter?

-   Because the current conversation around AI does violence to our usual understanding of basic terms (like intelligence)
    -   We need to do a bit of re-interpreting...
    -   ...particularly because AI can do the input-output part *really* well
-   (side effect) The Chinese Room is an excellent way of understanding what's going on inside some of the current tech

## The tech

-   AI = big umbrella term
-   More specific terms:
    -   *Algorithms* = rule-based ways of producing sensible output
    -   *Expert systems* = more sophisticated expertise-based production of output
    -   *Machine learning* = umbrella term for non-expertise-based production of output
    -   *Large Language Models* = a massively-succesful sub-species of machine learning

## So what's an algorithm?

::: columns
::: {.column width="25%"}
![](src/images/altair.jpg) [(Packard 1979)](https://www.goodreads.com/book/show/191062.The_Third_Planet_from_Altair)
:::

::: {.column width="60%"}
-   Algorithm = rule (roughly)
    -   if something happens, do something
-   made from expert input and evidence
:::
:::

## An example algorithm

![](src/images/nice_136.png){fig-align="center"}

## Related expertise-based tools

"See also..." references in indexes, library catalogues, wikipedia

. . .

![](src/images/cue.png) . . .

-   [Brilliant 1996 Master's dissertation](https://files.eric.ed.gov/fulltext/ED401916.pdf) looking at the state of "see also..." referencing in Ohio's public libraries

## How about something more complicated?


::: columns
:::: {.column width="35%"}

![](src/images/monitor.png)
::::

:::: {.column width="60%"}
- one problem with algorithms: how to handle conflicting information?
-   An expert system - [MYCIN](https://en.wikipedia.org/wiki/Mycin) [@shortliffe1975]
    -   designed to identify bacterial infections and suitable Rx
    -   600 rules, supplied by experts
    -   asks users a series of clinical questions
    -   combines the answers using a (fairly simple) inference system
    -   able to manage some conflicting information - unlike simpler algorithms

::::

:::

## Machine learning

-   A next step: can we provide learning rules to a system, and let it figure out the details for itself?

. . .

![https://commons.wikimedia.org/wiki/File:Supervised_machine_learning_in_a_nutshell.svg](src/images/sml.png)

## This is supervised learning

-   supervision = labelled observations used for training and testing
-   Lots of health examples with promising results:
    -   diabetic retinopathy [@mookiah2013]
    -   ECG [@aziz2021]
    -   fractures, melanoma, ...

## A dataset downside

::: columns
::: {.column width="40%"}
![[Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)](src/images/mnist.png)
:::

::: {.column width="50%"}
Producing labelled datasets is hard:

-   generally must be very large
-   generally requires expert classification
-   must be done with great accuracy
    -   scale bar problem [@winkler2021]
-   so dataset labelling is wildly expensive and thankless
    -   Is there a way of doing something similar without spending trillions classifying everything in the world by hand?
:::
:::

## Unsupervised learning

![](src/images/google.png){fig-align="center"}

## Unsupervised learning

![](src/images/explain.png){fig-align="center"}

## Unsupervised learning

![](src/images/go√∂gle.png){fig-align="center"}

## Unsupervised learning

-   No-one is writing a list of possible searches starting with "Large..."
-   Nor are they classifying searches into likely/unlikely, then training a model
-   Instead, the model is looking at data (searches, language, location, trends) and calculating probabilities
    -   [2011 blog post](https://googleblog.blogspot.com/2011/04/more-predictions-in-autocomplete.html)
    -   [2020 PR piece](https://blog.google/products/search/how-google-autocomplete-predictions-work/)
    -   [2020 build your own in JS](https://medium.com/analytics-vidhya/build-a-simple-autocomplete-model-with-your-own-google-search-history-ead26b3b6bd4)
-   The terminology gets confusing again at this point:
    -   some describe this as *deep learning*
    -   better to call this a *language model*

## Large language models

What if we were more ambitious with the scope of our language model?

. . .

::: columns
::: {.column width="30%"}
![](src/images/transformer.png)
:::

::: {.column width="60%"}
-   Find masses of language data
    -   chatGPT uses basically the whole web before September 2021
-   Build a model capable of finding patterns in that data
    -   Attention model used in chatGPT [@vaswani2017]
-   Allow the model to calculate probabilities based on those patterns
    -   lots of work going on at present allowing models to improve in response to feedback etc
:::
:::

## Large language models

-   superb at generating appropriate text, code, images, music...
-   but production vs understanding
    -   e.g. hallucinations, phantom functions...
-   training is extremely computationally expensive
    -   questions about inequality and regulatory moating
        -   no-one but FAANG-sized companies can afford to do this
    - training is also surprisingly manual

## Ethics

- your web content, my model, my paycheque
- where's the consent here?
- big serious worries about bias in some kinds of output
- rights violations via AI
- no settled questions around responsibility
- UK GDPR etc assume data is identifiable. That's not true in LLMs.

## Punchline

-   On balance, while there's hype here, there's also lots of substance and interest
-   LLMs have become *much* better at producing plausible output, across a *greatly* expanded area
-   A strength: fantastic ways for those with expertise to work faster
-   A danger: LLMs are great at producing truth-like output. Good enough so that some will be tempted to use them to extend their apparent expertise...
-   But big serious legal and ethical trouble ahead - we're not good at dealing with distributed responsibility

## Thumbs-up for specificity
+ many of the touted benefits are technology-specific
    + e.g. if we want to understand why decisions are getting made in a particular way, an expert system is better than a LLM
+ we should probably start asking "what do you mean by AI" whenever we're trying to make decisions about it

## Conclusion

1. The *intelligence* part of AI is as misleading as a swimming submarine
1. There are lots of different technologies that currently fall under the AI umbrella
1. points 1. and 2. really matter because of the hype

## Why the hype matters

- hype leads to perverse incentives and malfescience: call any rubbish AI, and get paid for it
- that means that both what we mean by AI, and what tech gets included, is extra-important at present - there's an industry out there that's profiting from blurring the boundaries

## Future sessions {.smaller}

```{r}
KINDR::training_sessions(start_date = params$date, n = 5)
```

{{< include footer.qmd >}}



